---
id: 'comprehensive-testing-strategy-at-scale'
title: Comprehensive Testing Strategy at Scale
section: Enterprise Scale
---

# Comprehensive Testing Strategy at Scale

# Chapter 18: The Final Frontier: When (and How) to Use Microfrontends

You've built a modular monolith. Your bounded contexts are clean, your ViewModels are framework-agnostic, and your domain events flow smoothly between modules. Everything works. The team ships features predictably. Tests run in milliseconds.

Then someone asks: "Should we split this into microfrontends?"

The answer is almost always: **not yet**.

Microfrontends aren't the natural evolution of good architecture—they're a **scaling solution for specific organizational problems**. They introduce operational complexity, runtime coordination challenges, and deployment overhead that most teams don't need. The modular monolith we've built throughout this book solves the vast majority of frontend scaling problems without those costs.

But sometimes—**sometimes**—microfrontends are exactly what you need.

This chapter explores when that "sometimes" arrives and how the architectural foundations we've established make the transition clean and reversible. We'll extract GreenWatch's Analytics module into a standalone microfrontend, demonstrating how proper modularity makes this transformation surgical rather than catastrophic.

## The Microfrontend Trap

Let's address the elephant in the architecture review room: microfrontends have become a solution looking for a problem.

The pitch sounds compelling: "We'll split our frontend into independent applications, each owned by a separate team, deployed independently, composed at runtime." It promises organizational autonomy, independent deployments, and technology flexibility.

The reality is messier. Most teams that adopt microfrontends prematurely discover they've traded well-understood complexity (managing a large codebase) for poorly-understood complexity (managing distributed frontend systems). They've added network boundaries, version coordination, shared state synchronization, and bundle size multiplication.

Here's what actually happens:

**Before microfrontends:**

```typescript
// Simple function call within the monolith
const analytics = await analyticsViewModel.generateReport(params);
```

**After microfrontends:**

```typescript
// Now you're doing distributed systems
const analytics = await fetch('/analytics-mfe/api/report', {
  method: 'POST',
  body: JSON.stringify(params),
  headers: {
    'X-Auth-Token': await getToken(), // Shared auth
    'X-Correlation-Id': correlationId, // Distributed tracing
  },
}).then((response) => {
  if (!response.ok) {
    // Handle network failures, timeouts, version mismatches...
    throw new NetworkError('Analytics MFE unavailable');
  }
  return response.json();
});
```

You've introduced:

- Network latency and failure modes
- Version coordination between microfrontends
- Shared authentication state management
- Distributed error handling
- Performance monitoring across boundaries
- Multiple bundle downloads

The modular monolith gives you **logical boundaries** without operational boundaries. That's usually what you actually want.

## When Microfrontends Make Sense

Microfrontends become viable when you face **organizational scaling problems that architectural modularity can't solve**. Specifically:

### 1. **Genuinely Independent Deployment Cycles**

Not "different teams want to deploy whenever they want" (that's a process problem), but "this module has fundamentally different deployment characteristics."

**Example:** GreenWatch's Analytics module processes time-series data using heavy computational libraries. The team updates statistical models weekly based on new research. These deployments have nothing to do with the core monitoring features, but every deployment forces a full application rebuild and cache invalidation.

The **entire application** gets a new version hash because one module changed:

```typescript
// Before: Analytics changes force new bundle hash
// app.a8b3c2d1.js contains everything
// Analytics update? Now it's app.f7e4d3c2.js
// All users download everything again

// After: Analytics is independent
// app.core.a8b3c2d1.js (unchanged for months)
// analytics.f7e4d3c2.js (updated weekly)
// Only analytics users download the new code
```

If your modules **don't** have genuinely independent deployment needs, you don't need microfrontends. You need better module boundaries.

### 2. **Extreme Performance Isolation**

When a module's performance characteristics fundamentally conflict with the rest of the application.

GreenWatch's Analytics module processes millions of sensor readings through statistical models. It uses WebAssembly for computations, loads 2MB of charting libraries, and maintains large in-memory datasets. This is **radically different** from the real-time monitoring UI, which needs to stay lightweight and responsive.

In a monolith, you can code-split aggressively, but you still share:

- The main thread (heavy analytics computations block UI updates)
- Memory space (large datasets compete with cached sensor data)
- Bundle parsing time (even with code splitting, the browser parses all vendor code)

A microfrontend with **dedicated resources** solves this:

```typescript
// Analytics runs in a separate iframe with dedicated resources
// Heavy computations don't block the main application thread
// Memory exhaustion in analytics doesn't crash monitoring
// Different performance budgets for different user needs
```

If your modules have **similar performance profiles**, code splitting and lazy loading are sufficient. You don't need process isolation.

### 3. **Team Scaling Beyond Module Ownership**

When you have **multiple teams** that need to work in the same bounded context without coordinating every change.

This is rare. Most "team scaling" problems are actually **communication problems** masked as technical problems. If your teams can't coordinate on a shared codebase, giving them separate repositories won't magically improve communication—it'll just make integration harder.

But sometimes it's real: You've acquired another company that has its own frontend team, their own deployment pipeline, their own tooling. Full integration would take 18 months and disrupt both teams' velocity. A microfrontend boundary gives you time to integrate gradually.

If your teams **can** coordinate effectively (stand-ups, shared PR reviews, common standards), module ownership in a monolith works better. You don't need repository isolation.

### 4. **Technology Migration**

When you need to **gradually migrate** from one framework to another without a rewrite.

The modular monolith we've built makes this relatively painless—you can migrate module by module **within** the monolith. But sometimes the migration itself becomes a political problem. Stakeholders get nervous about long-running migrations in the main codebase. Teams fear breaking the existing application.

Microfrontends provide psychological safety: the new technology is **completely isolated**. If it fails, you can roll back without touching the stable code.

```typescript
// Old application continues unchanged
// New features get built in the new framework
// Gradual migration without dual maintenance in one codebase
```

If you're **confident** in your migration strategy and your team embraces incremental change, migrating within the monolith is lower risk. You don't need separate applications.

## The GreenWatch Analytics Extraction

Let's walk through extracting GreenWatch's Analytics module into a microfrontend. We'll see how the architectural decisions we made throughout this book make this extraction **surprisingly clean**.

### Why Analytics Is the Perfect Candidate

The Analytics bounded context exhibits **all four microfrontend justifications**:

1. **Independent deployments:** Data science team updates statistical models weekly, completely independent of monitoring features
2. **Performance isolation:** Processes millions of data points through WebAssembly, needs dedicated resources
3. **Team scaling:** Analytics team works with data scientists who don't need to understand React component lifecycles
4. **Technology considerations:** Exploring GPU-accelerated computations that might require different runtime constraints

More importantly, Analytics has **clean boundaries** already:

```typescript
// src/contexts/analytics/domain/

export interface AnalyticsRepository {
  getHistoricalReadings(greenhouseId: string, range: DateRange): Observable<SensorReading[]>;
}

export interface StatisticalModelService {
  calculateTrends(data: SensorReading[]): TrendAnalysis;
  detectAnomalies(data: SensorReading[]): Anomaly[];
  predictConditions(history: SensorReading[]): Prediction[];
}

export class AnalyticsDomainEvents {
  static reportGenerated(report: AnalyticsReport): DomainEvent {
    return {
      type: 'analytics.report-generated',
      payload: report,
      timestamp: new Date(),
    };
  }
}
```

Notice what's **already** in place:

- Domain interfaces, not framework-specific implementations
- Observable-based data access (works across microfrontend boundaries)
- Domain events for cross-context communication
- No direct imports from other contexts

This is why we built modular foundations first. Extraction becomes a **deployment change**, not an architectural rewrite.

### Step 1: Create the Analytics Microfrontend Shell

We'll use **Module Federation** (Webpack 5's runtime module sharing) to load Analytics dynamically. Other approaches exist (iframe isolation, Web Components), but Module Federation gives us **shared dependencies** without duplication.

```typescript
// analytics-mfe/webpack.config.js
const ModuleFederationPlugin = require('webpack/lib/container/ModuleFederationPlugin');

module.exports = {
  plugins: [
    new ModuleFederationPlugin({
      name: 'analytics',
      filename: 'remoteEntry.js',
      exposes: {
        './AnalyticsModule': './src/AnalyticsModule.tsx',
        './AnalyticsViewModel': './src/application/AnalyticsViewModel.ts',
      },
      shared: {
        react: { singleton: true, requiredVersion: '^18.0.0' },
        'react-dom': { singleton: true, requiredVersion: '^18.0.0' },
        rxjs: { singleton: true, requiredVersion: '^7.8.0' },
      },
    }),
  ],
};
```

This configuration:

- **Exposes** the Analytics module as a remote entry point
- **Shares** React, ReactDOM, and RxJS as singletons (loaded once, shared between host and remote)
- Creates a separate bundle with independent versioning

The **key insight**: We're exposing both the **React component** (`AnalyticsModule`) and the **ViewModel** (`AnalyticsViewModel`). The ViewModel remains framework-agnostic, testable as a plain TypeScript class, and usable across microfrontend boundaries.

### Step 2: Configure the Host Application

```typescript
// host-app/webpack.config.js
const ModuleFederationPlugin = require('webpack/lib/container/ModuleFederationPlugin');

module.exports = {
  plugins: [
    new ModuleFederationPlugin({
      name: 'host',
      remotes: {
        analytics: 'analytics@http://localhost:3001/remoteEntry.js',
      },
      shared: {
        react: { singleton: true, requiredVersion: '^18.0.0' },
        'react-dom': { singleton: true, requiredVersion: '^18.0.0' },
        rxjs: { singleton: true, requiredVersion: '^7.8.0' },
      },
    }),
  ],
};
```

The host application now **consumes** Analytics as a remote module. In production, that URL would point to your CDN where the Analytics team deploys independently.

### Step 3: Load Analytics Dynamically

```typescript
// src/application/AppViewModel.ts
import { Observable, BehaviorSubject, from } from 'rxjs';
import { map, catchError } from 'rxjs/operators';

export class AppViewModel {
  private readonly _analyticsAvailable = new BehaviorSubject<boolean>(false);
  public readonly analyticsAvailable$ = this._analyticsAvailable.asObservable();

  private analyticsViewModel?: any; // Dynamic import, no compile-time dependency

  async loadAnalyticsModule(): Promise<void> {
    try {
      // @ts-ignore - Dynamic import of remote module
      const { AnalyticsViewModel } = await import('analytics/AnalyticsViewModel');

      // Instantiate with our existing services
      // The ViewModel doesn't know or care that it's in a microfrontend
      this.analyticsViewModel = new AnalyticsViewModel(
        this.analyticsRepository,
        this.statisticalModelService,
        this.eventBus,
      );

      this._analyticsAvailable.next(true);
    } catch (error) {
      console.error('Failed to load Analytics module:', error);
      // Graceful degradation - core app continues working
      this._analyticsAvailable.next(false);
    }
  }

  getAnalyticsViewModel(): any {
    if (!this.analyticsViewModel) {
      throw new Error('Analytics module not loaded');
    }
    return this.analyticsViewModel;
  }
}
```

Critical observations:

**The ViewModel contract doesn't change.** We instantiate `AnalyticsViewModel` exactly as we did in the monolith—with repository, service, and event bus dependencies. The ViewModel has **no idea** it's crossing a microfrontend boundary.

**Graceful degradation.** If the Analytics microfrontend fails to load (network issues, deployment problems, version conflicts), the core application continues functioning. We expose an observable that the UI can react to.

**No compile-time coupling.** The host application doesn't import Analytics types at build time. It loads them at runtime. This means Analytics can deploy new versions without forcing host recompilation.

### Step 4: Render Analytics Dynamically

```typescript
// src/components/AnalyticsRoute.tsx
import React, { Suspense, useEffect } from 'react';
import { useViewModel } from '../hooks/useViewModel';
import { AppViewModel } from '../application/AppViewModel';

// Lazy load the Analytics component
const AnalyticsModule = React.lazy(() =>
  // @ts-ignore
  import('analytics/AnalyticsModule')
);

export const AnalyticsRoute: React.FC = () => {
  const appViewModel = useViewModel(AppViewModel);
  const [analyticsAvailable] = useObservable(
    appViewModel.analyticsAvailable$,
    false
  );

  useEffect(() => {
    appViewModel.loadAnalyticsModule();
  }, [appViewModel]);

  if (!analyticsAvailable) {
    return (
      <div className="analytics-loading">
        <p>Loading Analytics module...</p>
        <p className="text-muted">
          Connecting to analytics service...
        </p>
      </div>
    );
  }

  return (
    <Suspense fallback={<AnalyticsLoadingSkeleton />}>
      <AnalyticsModule
        viewModel={appViewModel.getAnalyticsViewModel()}
      />
    </Suspense>
  );
};
```

React's `Suspense` handles the async loading, showing a loading state while the remote bundle downloads. If Analytics deploys a new version, users get it on next navigation—no full-page refresh required.

### Step 5: Maintain Shared ViewModels

Here's where our architecture really shines. The **ViewModel lives in both places**:

```typescript
// Shared between host and remote
// analytics-mfe/src/application/AnalyticsViewModel.ts
// (identical copy in host for type safety during development)

export class AnalyticsViewModel {
  private readonly _report = new BehaviorSubject<AnalyticsReport | null>(null);
  public readonly report$ = this._report.asObservable();

  constructor(
    private readonly repository: AnalyticsRepository,
    private readonly modelService: StatisticalModelService,
    private readonly eventBus: EventBus,
  ) {}

  async generateReport(params: ReportParams): Promise<void> {
    const readings = await firstValueFrom(this.repository.getHistoricalReadings(params.greenhouseId, params.range));

    const trends = this.modelService.calculateTrends(readings);
    const anomalies = this.modelService.detectAnomalies(readings);

    const report: AnalyticsReport = {
      trends,
      anomalies,
      generatedAt: new Date(),
    };

    this._report.next(report);

    // Domain event works across microfrontend boundaries
    this.eventBus.publish(AnalyticsDomainEvents.reportGenerated(report));
  }
}
```

**This is the same code we wrote in Chapter 6.** Nothing changed. The ViewModel:

- Remains framework-agnostic
- Uses observables for reactive state
- Publishes domain events through the event bus
- Has no awareness of deployment topology

We can **test this ViewModel in the host application's test suite** even though it's deployed separately. We can share it between React (host) and Vue (if we migrate Analytics later). The microfrontend boundary is a **runtime deployment concern**, not an architectural one.

### Step 6: Handle Cross-Context Communication

Domain events need to flow **across microfrontend boundaries**. Our event bus implementation needs a small enhancement:

```typescript
// shared/infrastructure/CrossMicrofrontendEventBus.ts
import { Subject, Observable } from 'rxjs';
import { filter } from 'rxjs/operators';

export class CrossMicrofrontendEventBus implements EventBus {
  private readonly events = new Subject<DomainEvent>();
  private readonly broadcastChannel: BroadcastChannel;

  constructor() {
    // BroadcastChannel enables communication between same-origin contexts
    this.broadcastChannel = new BroadcastChannel('greenwatch-events');

    // Listen for events from other microfrontends
    this.broadcastChannel.onmessage = (event) => {
      this.events.next(event.data);
    };
  }

  publish(event: DomainEvent): void {
    // Publish locally
    this.events.next(event);

    // Broadcast to other microfrontends
    this.broadcastChannel.postMessage(event);
  }

  subscribe<T extends DomainEvent>(eventType: string): Observable<T> {
    return this.events.pipe(filter((event) => event.type === eventType)) as Observable<T>;
  }
}
```

Now when Analytics publishes `analytics.report-generated`, the Monitoring context in the host application receives it **even though they're in different bundles**. The domain event pattern scales across deployment boundaries.

**Alternative approaches:**

- **Custom events on window object** (simpler, but couples to browser globals)
- **Shared Redux store** (works, but reintroduces framework coupling)
- **Backend event relay** (more reliable for complex workflows, adds latency)

BroadcastChannel is the sweet spot: standard browser API, same-origin restriction for security, low latency.

## What We Gained (and Lost)

### Gains

**Independent deployments:** Analytics team ships weekly model updates without touching the core application. No coordinated releases, no cache invalidation for monitoring users.

**Performance isolation:** Heavy statistical computations run in their own thread context (if using iframes) or at least their own bundle parsing budget. A memory leak in analytics doesn't crash the monitoring dashboard.

**Team autonomy:** Analytics team owns their deployment pipeline, their testing strategy, their performance budget. They can experiment with WebAssembly, GPU acceleration, or different chart libraries without host application approval.

**Technology flexibility:** Want to try Svelte for the analytics UI? You can. The ViewModel contract doesn't change, and the host application doesn't care about your view layer choice.

### Losses

**Operational complexity:** You now run **two applications**. Two build processes, two deployment pipelines, two monitoring dashboards, two sets of logs to correlate when debugging issues.

**Version coordination:** Module Federation helps, but you still need to ensure the host and remote agree on shared dependency versions. A breaking change in RxJS requires coordinated updates.

**Network latency:** Loading the Analytics module adds a network round-trip. For users on slow connections, that's noticeable. Code splitting in a monolith is faster.

**Bundle size multiplication:** Despite shared dependencies, you've increased total JavaScript download. The remote entry point adds overhead. You're downloading module loading infrastructure.

**Debugging difficulty:** Stack traces now cross bundle boundaries. Source maps need careful configuration. Error monitoring requires distributed tracing. When something breaks, "which version of which microfrontend" becomes a question you'll ask often.

**Testing complexity:** Integration tests now require running multiple applications. Your CI pipeline needs to orchestrate containers. End-to-end tests become flakier because they depend on network behavior.

## The Decision Framework

Use this framework when evaluating microfrontends:

### Start Here: Can Module Boundaries Solve This?

- **If** teams are stepping on each other's code → Create clearer module boundaries with enforced dependency rules
- **If** deployments are too risky → Improve automated testing and feature flags
- **If** the codebase feels too large → Implement better code organization and lazy loading
- **If** builds are too slow → Optimize your build pipeline and use incremental compilation

**Only proceed** if module boundaries fundamentally can't address your problem.

### Evaluate Each Context Independently

Not all bounded contexts should become microfrontends. Evaluate each:

```typescript
interface MicrofrontendCandidate {
  deploymentFrequency: 'hourly' | 'daily' | 'weekly' | 'monthly';
  performanceProfile: 'lightweight' | 'standard' | 'computationally-intensive';
  teamOwnership: 'shared' | 'dedicated' | 'external';
  userOverlap: 'all-users' | 'most-users' | 'power-users-only';
  technicalDependencies: 'tightly-coupled' | 'loosely-coupled' | 'independent';
}

function evaluateMicrofrontendViability(
  context: MicrofrontendCandidate,
): 'good-candidate' | 'maybe' | 'keep-in-monolith' {
  // Good candidates: frequent independent deployments, heavy performance needs,
  // dedicated team, specialized user base, minimal dependencies
  if (
    context.deploymentFrequency === 'daily' &&
    context.performanceProfile === 'computationally-intensive' &&
    context.teamOwnership === 'dedicated' &&
    context.userOverlap === 'power-users-only' &&
    context.technicalDependencies === 'independent'
  ) {
    return 'good-candidate';
  }

  // Keep in monolith: shared ownership, all users need it, tightly coupled
  if (
    context.teamOwnership === 'shared' ||
    context.userOverlap === 'all-users' ||
    context.technicalDependencies === 'tightly-coupled'
  ) {
    return 'keep-in-monolith';
  }

  return 'maybe';
}
```

Apply this to GreenWatch:

- **Analytics:** Good candidate (daily deployments, computationally intensive, dedicated team, power users only, independent)
- **Monitoring:** Keep in monolith (all users, tightly coupled to device management, shared team ownership)
- **Device Management:** Keep in monolith (all users, foundational to everything else)
- **Alerts:** Keep in monolith (all users, frequent cross-context communication)

### Consider the Reversibility

Can you **go back** if microfrontends don't work out?

Our architecture makes this feasible:

- ViewModels are shared code—you can move them back into the monolith without changes
- Domain events work identically in monolith and microfrontend configurations
- No framework lock-in means you can merge codebases without rewriting

If your microfrontend extraction requires **rewriting domain logic** or **changing communication patterns**, you've coupled your business logic to your deployment strategy. That's backwards.

### Calculate the Real Costs

**Development time:**

- Monolith module: 2-3 weeks to build, well-understood patterns
- Microfrontend: Add 1-2 weeks for Module Federation setup, testing infrastructure, deployment pipeline

**Ongoing maintenance:**

- Monolith: One deployment pipeline, one monitoring system, centralized logging
- Microfrontend: Multiply everything by number of microfrontends, plus coordination overhead

**Performance:**

- Monolith with code splitting: First load includes shell, lazy load modules on demand
- Microfrontend: First load includes shell + Module Federation runtime, network request for each microfrontend on demand

Run the numbers honestly. Microfrontends often cost more than teams expect.

## Implementation Patterns

### Pattern 1: Shell Architecture

The host application becomes a **minimal shell** that orchestrates microfrontends:

```typescript
// src/application/ShellViewModel.ts
export class ShellViewModel {
  private readonly microfrontends = new Map<string, MicrofrontendConfig>();

  registerMicrofrontend(config: MicrofrontendConfig): void {
    this.microfrontends.set(config.name, config);
  }

  async loadMicrofrontend(name: string): Promise<void> {
    const config = this.microfrontends.get(name);
    if (!config) {
      throw new Error(`Microfrontend ${name} not registered`);
    }

    // Dynamic import with error handling
    try {
      await import(/* webpackIgnore: true */ config.remoteEntry);
    } catch (error) {
      // Fallback or graceful degradation
      console.error(`Failed to load ${name}:`, error);
    }
  }
}
```

The shell handles:

- Authentication (shared auth state)
- Navigation (routing between microfrontends)
- Shared UI components (header, footer, navigation)
- Error boundaries (isolate microfrontend failures)

**Keep the shell minimal.** If you put business logic in the shell, you've created a distributed monolith—the worst of both worlds.

### Pattern 2: Shared ViewModel Layer

ViewModels live in a **shared package** that both host and remotes consume:

```typescript
// packages/shared-viewmodels/package.json
{
  "name": "@greenwatch/shared-viewmodels",
  "version": "2.3.1",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "peerDependencies": {
    "rxjs": "^7.8.0"
  }
}

// Host and Analytics both depend on this package
// Version alignment happens at package dependency resolution
// Breaking changes are explicit version bumps
```

This ensures:

- **Type safety** across microfrontend boundaries (TypeScript knows the contract)
- **Version coordination** (package manager enforces compatible versions)
- **Shared testing** (test utilities work for all consumers)

**Alternative:** You could use runtime contracts (TypeScript interfaces published as JSON schemas), but you lose compile-time safety. Shared packages are simpler until you hit multi-repository scaling problems.

### Pattern 3: Event-Driven Integration

Microfrontends communicate through **domain events only**—no direct function calls:

```typescript
// ❌ Don't: Direct coupling across microfrontends
analytics.onReportGenerated((report) => {
  monitoring.updateDashboard(report); // Now Analytics knows about Monitoring
});

// ✅ Do: Event-driven decoupling
eventBus.publish(AnalyticsDomainEvents.reportGenerated(report));

// Monitoring subscribes independently
eventBus.subscribe<ReportGeneratedEvent>('analytics.report-generated').subscribe((event) => {
  this.updateDashboard(event.payload);
});
```

This maintains **loose coupling** even across deployment boundaries. If you remove the Analytics microfrontend, Monitoring just stops receiving those events—no code changes required.

### Pattern 4: Progressive Enhancement

Load microfrontends **progressively** based on user needs:

```typescript
// Core users never download Analytics code
// Power users get it lazily when they navigate to analytics
// Admin users get it preloaded on application startup

export class ProgressiveLoadingStrategy {
  constructor(
    private readonly userRole: UserRole,
    private readonly shellViewModel: ShellViewModel,
  ) {}

  async initialize(): Promise<void> {
    // Always load core functionality
    await this.shellViewModel.loadMicrofrontend('monitoring');

    // Preload for admins (they'll use it soon)
    if (this.userRole === 'admin') {
      await this.shellViewModel.loadMicrofrontend('analytics');
    }

    // Lazy load for power users (on-demand)
    // Nothing for basic users (they never see it)
  }
}
```

This optimizes initial load time while ensuring advanced features are available when needed.

## Testing Across Boundaries

### Unit Testing ViewModels

**Nothing changes.** ViewModels remain plain TypeScript classes:

```typescript
// analytics-mfe/src/application/__tests__/AnalyticsViewModel.test.ts
describe('AnalyticsViewModel', () => {
  it('generates reports from sensor readings', async () => {
    // Same test we wrote in Chapter 7
    const repository = createMockRepository();
    const modelService = createMockModelService();
    const eventBus = createMockEventBus();

    const viewModel = new AnalyticsViewModel(repository, modelService, eventBus);

    await viewModel.generateReport({
      greenhouseId: 'gh-1',
      range: { start: new Date('2024-01-01'), end: new Date('2024-01-31') },
    });

    expect(eventBus.publish).toHaveBeenCalledWith(
      expect.objectContaining({
        type: 'analytics.report-generated',
      }),
    );
  });
});
```

The microfrontend boundary doesn't affect unit tests. They run in milliseconds. No network, no containers, no coordination.

### Integration Testing

Test the **Module Federation integration**:

```typescript
// host-app/__tests__/integration/analytics-loading.test.ts
import { screen, waitFor } from '@testing-library/react';
import { setupTestEnvironment } from './test-utils';

describe('Analytics Microfrontend Integration', () => {
  it('loads analytics module dynamically', async () => {
    const { navigateToAnalytics, getByTestId } = setupTestEnvironment();

    await navigateToAnalytics();

    await waitFor(() => {
      expect(getByTestId('analytics-dashboard')).toBeInTheDocument();
    });
  });

  it('handles analytics loading failure gracefully', async () => {
    // Mock network failure
    mockModuleFederationFailure('analytics');

    const { navigateToAnalytics } = setupTestEnvironment();
    await navigateToAnalytics();

    expect(screen.getByText(/Analytics unavailable/i)).toBeInTheDocument();
    // Core app still functions
    expect(screen.getByTestId('monitoring-dashboard')).toBeInTheDocument();
  });
});
```

Use **test doubles** for the remote module during CI. Full microfrontend integration tests are expensive—run them selectively.

### Contract Testing

Ensure the host and remote **agree on contracts**:

```typescript
// packages/shared-contracts/__tests__/analytics.contract.test.ts
import { AnalyticsViewModel } from '@greenwatch/shared-viewmodels';

describe('Analytics Contract', () => {
  it('AnalyticsViewModel exposes required interface', () => {
    const viewModel = new AnalyticsViewModel({} as any, {} as any, {} as any);

    // Host depends on these properties existing
    expect(viewModel).toHaveProperty('report$');
    expect(viewModel).toHaveProperty('generateReport');
    expect(typeof viewModel.generateReport).toBe('function');
  });
});
```

Contract tests catch **breaking changes** before they reach production. If Analytics team changes the ViewModel interface, the contract test fails in CI.

## When to Stay Monolithic

Let's be explicit: **most applications should remain modular monoliths**.

You don't need microfrontends if:

- You have **fewer than 50 developers** working on the frontend
- Your modules don't have **wildly different deployment cycles** (daily vs. monthly)
- Performance problems can be solved with **code splitting and lazy loading**
- Your team can coordinate **pull requests and code reviews** effectively
- You don't have **organizational boundaries** that require repository isolation

The modular monolith we've built gives you:

- **Logical boundaries** (bounded contexts, clean dependencies)
- **Independent testing** (test each module in isolation)
- **Code organization** (clear structure, enforced by linting)
- **Lazy loading** (users only download code they need)

That's **90% of what microfrontends promise** without the operational cost.

## The Path Forward

If you do extract microfrontends, do it **incrementally**:

1. **Start with one context** (the most independent, like Analytics)
2. **Prove the value** (faster deployments? Better performance? Clearer ownership?)
3. **Measure the costs** (operational overhead, debugging complexity, development slowdown)
4. **Decide deliberately** whether to extract more contexts

Don't commit to "microfrontends for everything" upfront. That's **architectural astronautics**—designing for scale you don't have yet.

The beauty of our modular foundation is that you can **always extract later**. Clean bounded contexts, framework-agnostic ViewModels, and event-driven communication make extraction surgical rather than catastrophic.

But extraction is **reversible**, too. If microfrontends don't deliver value, you can merge contexts back into the monolith. The domain logic doesn't change. The ViewModel tests don't change. You just change deployment topology.

That's the real power of architecture: **options**. You can scale up or down based on **actual needs** rather than speculative futures.

---

**Next**, we'll explore the future of frontend architecture—how AI-assisted development, edge computing, and evolving framework patterns will interact with the modular foundations we've established. The tools change, but the principles remain.
